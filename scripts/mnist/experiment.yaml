!obj:pylearn2.scripts.train.Train {
    # dataset below is now (temporarily) obsolete
    "dataset": &data !obj:pylearn2.datasets.mnist.MNIST {
        "which_set": 'train',
        "shuffle": True,
        "one_hot": True,
        "binarize": 'threshold',
    },
    "model": &model !obj:DBM.dbm.DBM {
        "seed" : 123141,
        "n_u": [784,400,100],
        "lr_spec": {
            'type': 'linear',
            "start": 0.001,
            "end": 0.001,
        },
        "flags": {
            'enable_natural': True,
            'enable_natural_diag': False,
            'enable_centering': True,
            'enable_warm_start': False,
            'precondition': 'None',
            'mlbiases': True,
            'lincg': False,
            'minres': False,
            'minresQLP': True,
        },
        "lr_timestamp": [0.],
        "lr_mults": {},
        "pos_mf_steps": 0,
        "pos_sample_steps": 5,
        "neg_sample_steps": 5,
        "iscales": {'W1': 0.001, 'W2': 0.001},
        "clip_min": {},
        "l1": {'W1': 0.0, 'W2': 0.0},
        "batch_size": &batch_size 256,
        "computational_bs": 0,
        "cg_params": {
            'rtol': 0.000001,
            'damp': 0.1,
            'maxiter': 100,
        },
        "my_save_path": 'dbm',
        "save_at": [1000,5000],
        "save_every": 1000,
        "max_updates": 1000000,
    },
    "algorithm": !obj:pylearn2.training_algorithms.default.DefaultTrainingAlgorithm {
        "batch_size": *batch_size,
        "batches_per_iter" : 1000,
        "monitoring_batches": 1,
        "monitoring_dataset": *data,
    },
    "callbacks": [
        !obj:DBM.scripts.likelihood.ais_callback.pylearn2_ais_callback {
            "ais_interval": 1000,
            "trainset": *data,
            "testset": !obj:pylearn2.datasets.mnist.MNIST {
                "which_set": 'test',
                "one_hot": True,
                "binarize": 'threshold',
            },
        }
    ]
}
